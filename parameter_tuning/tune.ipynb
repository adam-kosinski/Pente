{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class EvaluationModel():\n",
    "    def __init__(self, split_indices, blend_range=2):\n",
    "        self.split_indices = split_indices\n",
    "        self.blend_range = blend_range\n",
    "        self.fitted = False\n",
    "\n",
    "        split_indices.sort()\n",
    "        assert split_indices[0] == 0\n",
    "\n",
    "        n_clfs = len(split_indices)\n",
    "        self.clfs = [LogisticRegression() for _ in range(n_clfs)]\n",
    "        self.train_scores = []\n",
    "        self.data_fractions = []\n",
    "\n",
    "        # find weights for properly blending together classifiers\n",
    "        weights = []\n",
    "        for i in range(n_clfs):\n",
    "            # set the area belonging to this classifier as weight 1\n",
    "            unblended = np.zeros((split_indices[-1] + 2*blend_range + 1))\n",
    "            start = max(0, split_indices[i])\n",
    "            if i < len(split_indices)-1:\n",
    "                stop = split_indices[i+1]\n",
    "            else:\n",
    "                stop = len(unblended) + 1\n",
    "            unblended[start:stop] = 1\n",
    "\n",
    "            # blend it with the zeros around the edges, appending copies of the start to the start to make up for valid convolution\n",
    "            if blend_range != 0:\n",
    "                blend_kernel = np.ones(blend_range*2) / (blend_range*2)\n",
    "                unblended = np.concatenate(\n",
    "                    ([unblended[0]]*blend_range, unblended))\n",
    "                weights.append(np.convolve(\n",
    "                    unblended, blend_kernel, mode=\"valid\"))\n",
    "            else:\n",
    "                weights.append(unblended)\n",
    "\n",
    "        self.clf_weights = np.array(weights).T\n",
    "\n",
    "    def get_data_weights(self, X, clf_index=None):\n",
    "        # X is a pandas dataframe, should include \"move-index\" column\n",
    "\n",
    "        # floor the move indices so that if larger than the size of self.clf_weights, we just take the last weight\n",
    "        move_indices = np.minimum(\n",
    "            self.clf_weights.shape[0]-1, X[\"move-index\"].values)\n",
    "        return self.clf_weights[move_indices, clf_index]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # X is a pandas dataframe, should include \"move-index\" column\n",
    "        # fit each of the classifiers on their region of data (by weighting the data)\n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "        X_no_move_index = X.drop(\"move-index\", axis=1)\n",
    "        self.coef_names = X_no_move_index.columns\n",
    "\n",
    "        for i, clf in enumerate(self.clfs):\n",
    "            weights = self.get_data_weights(X, i)\n",
    "            self.data_fractions.append(np.mean(weights))\n",
    "            clf.fit(X_no_move_index, y, sample_weight=weights)\n",
    "\n",
    "        self.fitted = True\n",
    "        for i, clf in enumerate(self.clfs):\n",
    "            self.train_scores.append(self.score(X, y, i))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_no_move_index = X.drop(\"move-index\", axis=1)\n",
    "        decision_scores = []\n",
    "        for i, clf in enumerate(self.clfs):\n",
    "            weights = self.get_data_weights(X, i)\n",
    "            logits = X_no_move_index @ clf.coef_.T + clf.intercept_\n",
    "            decision_scores.append(np.multiply(weights, np.squeeze(logits)))\n",
    "\n",
    "        mean_decision_scores = np.mean(np.array(decision_scores), axis=0)\n",
    "        return (mean_decision_scores > 0).astype(int)\n",
    "\n",
    "    def score(self, X, y, clf_index=None):\n",
    "        if not self.fitted:\n",
    "            raise Exception(\"Not fitted yet\")\n",
    "\n",
    "        if clf_index is None:\n",
    "            return accuracy_score(self.predict(X), y)\n",
    "\n",
    "        relevant_points_mask = self.get_data_weights(X, clf_index) > 0\n",
    "        pred = self.predict(X)[relevant_points_mask]\n",
    "        gt = y[relevant_points_mask]\n",
    "        return accuracy_score(pred, gt)\n",
    "\n",
    "    def plot_coefs(self, X_test=None, y_test=None, loco=False):\n",
    "        if not self.fitted:\n",
    "            raise Exception(\"Not fitted yet\")\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=2, ncols=len(self.clfs), figsize=(14, 12))\n",
    "\n",
    "        if loco:\n",
    "            print(f\"Calculating variable importances\")\n",
    "            loco_importances = self.get_loco_importance(\n",
    "                self.X_train, self.y_train, relevant_only=True)\n",
    "\n",
    "        for i, clf in enumerate(self.clfs):\n",
    "            axis = axes[0] if len(self.clfs) == 1 else axes[0][i]\n",
    "            axis.barh(self.coef_names, clf.coef_[0])\n",
    "            axis.barh([\"bias\"], clf.intercept_[0])\n",
    "\n",
    "            # title\n",
    "            if i < len(self.split_indices)-1:\n",
    "                clf_name = f\"{self.split_indices[i]} ≤ move index ≤ {self.split_indices[i+1]}\"\n",
    "            else:\n",
    "                clf_name = f\"{self.split_indices[i]} ≤ move index\"\n",
    "            title = f\"{clf_name} ({100*self.data_fractions[i]:.0f}% data)\\n\" \\\n",
    "                    f\"Train accuracy: {self.train_scores[i]:.4f}\"\n",
    "            if X_test is not None and y_test is not None:\n",
    "                title += f\"\\nTest accuracy: {self.score(X_test, y_test, i):.4f}\"\n",
    "            axis.set_title(title)\n",
    "\n",
    "            if loco:\n",
    "                loco_axis = axes[1] if len(self.clfs) == 1 else axes[1][i]\n",
    "                loco_axis.barh(self.coef_names, loco_importances[:, i])\n",
    "                loco_axis.set_title(\n",
    "                    \"Accuracy reduction when predictor is left out,\\nfor positions where predictor is nonzero\")\n",
    "\n",
    "        suptitle = f\"Train accuracy: {self.score(self.X_train, self.y_train):.4f}\"\n",
    "        if X_test is not None and y_test is not None:\n",
    "            suptitle += f\"\\nTest accuracy: {self.score(X_test, y_test):.4f}\"\n",
    "        fig.suptitle(suptitle)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_loco_importance(self, X, y, relevant_only=True):\n",
    "        # relevant_only means only look at data points where the predictor value was nonzero\n",
    "        orig_clf = EvaluationModel(self.split_indices, self.blend_range)\n",
    "        orig_clf.fit(X, y)\n",
    "        importances = []\n",
    "        # try leaving each covariate out and seeing how the score decreases\n",
    "        for covar in X.columns:\n",
    "            if covar == \"move-index\":\n",
    "                continue\n",
    "            X_loco = X.drop(covar, axis=1)\n",
    "            clf = EvaluationModel(self.split_indices, self.blend_range)\n",
    "            clf.fit(X_loco, y)\n",
    "\n",
    "            if relevant_only:\n",
    "                irrelevant = np.where(np.squeeze(X[covar].values) == 0)[0]\n",
    "                clf_importances = [\n",
    "                    orig_clf.score(X.drop(irrelevant), y.drop(irrelevant), i) - clf.score(X_loco.drop(irrelevant), y.drop(irrelevant), i) for i in range(len(self.clfs))]\n",
    "            else:\n",
    "                clf_importances = [\n",
    "                    orig_clf.score(X, y, i) - clf.score(X_loco, y, i) for i in range(len(self.clfs))]\n",
    "\n",
    "            importances.append(clf_importances)\n",
    "\n",
    "        return np.array(importances)\n",
    "\n",
    "    def print_javascript_params(self):\n",
    "        if not self.fitted:\n",
    "            raise Exception(\"Not fitted yet\")\n",
    "        pass\n",
    "\n",
    "\n",
    "def split_data(X, y, train_fraction):\n",
    "    assert len(X) == len(y)\n",
    "    assert train_fraction > 0 and train_fraction <= 1\n",
    "    split_idx = int(len(X) * train_fraction)\n",
    "    # split (note that pandas slice indices are both inclusive)\n",
    "    return X.loc[:split_idx-1], X.loc[split_idx:], y.loc[:split_idx-1], y.loc[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"features.csv\")\n",
    "X = data.drop([\"won\"], axis=1)\n",
    "y = data[\"won\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "def check_collinearity(data, exclude):\n",
    "    X = data.drop([\"won\", \"move-index\"] + exclude, axis=1)\n",
    "    # check collinearity using variance inflation factor\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "    print(vif_data)\n",
    "\n",
    "check_collinearity(data, exclude=[])\n",
    "# check_collinearity(data, exclude=[\"my-4-captures\", \"opp-captures\", \"opp-4-captures\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.7461524854059791\n",
      "testing 0.71784349794821\n"
     ]
    }
   ],
   "source": [
    "# original model\n",
    "model = EvaluationModel([0, 19], blend_range=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"training\", model.score(X_train, y_train))\n",
    "print(\"testing\", model.score(X_test, y_test))\n",
    "# model.plot_coefs(X_test, y_test, loco=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.7457633115160092\n",
      "testing 0.7181265034668176\n"
     ]
    }
   ],
   "source": [
    "model = EvaluationModel([0, 19], blend_range=2)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"training\", model.score(X_train, y_train))\n",
    "print(\"testing\", model.score(X_test, y_test))\n",
    "# model.plot_coefs(X_test, y_test, loco=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.7488413231912259\n",
      "testing 0.7131739068911844\n"
     ]
    }
   ],
   "source": [
    "model = EvaluationModel([0, 5, 10, 15, 20, 25, 30, 35], blend_range=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"training\", model.score(X_train, y_train))\n",
    "print(\"testing\", model.score(X_test, y_test))\n",
    "# model.plot_coefs(X_test, y_test, loco=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
